{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fichier de nettoyage des données avant leur analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "# Set the working directory\n",
    "download_dir = \"../../RAW\"\n",
    "prod_dir = \"../../PROD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nettoyage des données LCZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des données LCZ\n",
    "subfold_lcz = \"LCZ\"\n",
    "\n",
    "# La liste théorique des fichiers à télécharger\n",
    "to_download = pd.read_csv(os.path.join(download_dir, subfold_lcz, \"to_download.csv\"))\n",
    "to_download[\"title_clean\"] = to_download[\"title\"].str.replace(\".zip\", \"\")\n",
    "\n",
    "# Ce qui est dans le dossier LCZ\n",
    "actually_downloaded = os.listdir(os.path.join(download_dir, subfold_lcz))\n",
    "\n",
    "# Ce qui est téléchargé\n",
    "lcz_folders = [f for f in actually_downloaded if f in to_download[\"title_clean\"].values]    \n",
    "\n",
    "# Le fichier des communes\n",
    "communes = gpd.read_file(os.path.join(prod_dir, \"geo/admin\", \"communes_2024.shp\"))\n",
    "communes = communes[[\"label\", \"official_c\", \"geometry\"]]\n",
    "\n",
    "\n",
    "# On charge les données FILOSOFI\n",
    "subfold_filosofi = \"INSEE/FILOSOFI/2019/CARREAUX_200M\"\n",
    "filosofi = gpd.read_file(os.path.join(download_dir, subfold_filosofi, \"carreaux_200m_met.shp\"))\n",
    "\n",
    "\n",
    "# On créé un dataframe pour stocker les résultats par commune\n",
    "\n",
    "summary_tot = pd.DataFrame(columns=['lcz', 'official_c', 'label', 'surf_lcz_com', 'surf_com_official',\n",
    "       'surf_lcz_id_com', 'share'])\n",
    "\n",
    "\n",
    "# On crée une fonction pour calculer les données pondérées\n",
    "def weighted_filo(datbase, weight_col, values_col):\n",
    "    copy = datbase.copy()\n",
    "    for value_col in values_col:\n",
    "        copy[value_col+\"_w\"] = copy[weight_col] * copy[value_col]\n",
    "    return copy\n",
    "\n",
    "os.makedirs(os.path.join(prod_dir, \"geo/lcz/filo_com\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traitement de la zone  lcz-spot-2022-marseille ( 83 / 83 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pl/xywgn7qd4sv_s094vn5h3dtr0000gn/T/ipykernel_42309/2263166504.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  summary_tot = pd.concat([summary_tot, summary])\n",
      "/var/folders/pl/xywgn7qd4sv_s094vn5h3dtr0000gn/T/ipykernel_42309/2263166504.py:58: UserWarning: `keep_geom_type=True` in overlay resulted in 44 dropped geometries of different geometry types than df1 has. Set `keep_geom_type=False` to retain all geometries\n",
      "  filo_lcz = gpd.overlay(gdf_com.filter(\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(lcz_folders)):\n",
    "    print(\"Traitement de la zone \", lcz_folders[i], \"(\", i+1, \"/\", len(lcz_folders), \")\")\n",
    "\n",
    "    # On charge le fichier\n",
    "    files = os.listdir(os.path.join(download_dir, subfold_lcz,lcz_folders[i]))\n",
    "    file = [f for f in files if f.endswith(\".shp\")][0]\n",
    "    gdf = gpd.read_file(os.path.join(download_dir, subfold_lcz, lcz_folders[i], file))\n",
    "    # gdf = gdf.filter(items=[\"geometry\",\"identifier\",\"lcz\",\"lcz_int\",\"hre\",\"are\"])\n",
    "    # On calcule l'aire de chaque polygone\n",
    "    gdf['surf_lcz_id'] = gdf.area/10**6 # On passe en km2\n",
    "\n",
    "    # On dissout pour obtenir le polygone de la zone\n",
    "    gdf_zone = gdf.dissolve()\n",
    "    # On fait une jointure spatiale avec le fichier des communes\n",
    "    communes_lcz = communes.sjoin(gdf_zone, how=\"inner\")\n",
    "    # On récupère les codes officiels des communes qui sont dans la zone\n",
    "    codes = communes_lcz.official_c.unique()\n",
    "\n",
    "\n",
    "    # On calcule l'aire de chaque commune\n",
    "    communes_lcz[\"surf_com_official\"] = communes_lcz.area/10**6\n",
    "\n",
    "\n",
    "    # On joint à la table des communes et on calcule la part de la commune dans la zone\n",
    "    communes_in_lcz = communes[communes[\"official_c\"].isin(codes)].merge(communes_lcz.filter(items=[\"official_c\",\"surf_com_official\"]), on=\"official_c\", how=\"left\")\n",
    "    communes_in_lcz = communes_in_lcz.filter(items=[\"official_c\",\"surf_com_official\",\"geometry\",\"label\"])\n",
    "\n",
    "    # On divise les zones LCZ par commune\n",
    "    gdf_com = gdf.overlay(communes_in_lcz, how=\"intersection\")\n",
    "    gdf_com[\"surf_lcz_id_com\"] = gdf_com.area/10**6\n",
    "\n",
    "    # On calcule la surface LCZ par commune\n",
    "    gdf_surf_com = (gdf_com\n",
    "                    .filter(items=[\"official_c\",\"surf_lcz_id_com\"])\n",
    "                    .groupby(\"official_c\").sum().reset_index())\n",
    "    gdf_surf_com = gdf_surf_com.rename(columns={\"surf_lcz_id_com\":\"surf_lcz_com\"})\n",
    "    gdf_com = gdf_com.merge(gdf_surf_com, on=\"official_c\",how=\"left\")\n",
    "\n",
    "    # On calcule par commune la répartition des surfaces LCZ\n",
    "    summary = (gdf_com\n",
    "            .filter(items=[\"lcz\",\"surf_lcz_id_com\",\"official_c\",\n",
    "                            \"label\",\"surf_lcz_com\",\"surf_com_official\",\"hre\",\"bur\"])\n",
    "            .groupby([\"lcz\",\"official_c\",\"label\",\"surf_lcz_com\",\"surf_com_official\"])\n",
    "            .sum())\n",
    "    summary.reset_index(inplace=True)\n",
    "    summary[\"share\"] = summary.surf_lcz_id_com/summary.surf_lcz_com\n",
    "\n",
    "\n",
    "    # On ajoute à la table globale\n",
    "    summary_tot = pd.concat([summary_tot, summary])\n",
    "\n",
    "    # On effectue la fusion avec les données FILOSOFI\n",
    "    ## On commence par ne conserver que l'id du carreau, la superficie et la géometrie\n",
    "    filo_geo = filosofi.filter(items=[\"geometry\",\"idcar_200m\"])\n",
    "\n",
    "    # On joint les données FILOSOFI par un overlay\n",
    "    filo_lcz = gpd.overlay(gdf_com.filter(\n",
    "        items=[\"lcz\",\"geometry\",\"hre\",\"bur\"]), \n",
    "        filo_geo, how=\"intersection\")\n",
    "\n",
    "    # H : On augmente la hauteur moyenne mini à 4m pour les zones résidentielles si la valeur est égale à 0 \n",
    "    # (une valeur de 0 semble illogique et a également pour effet de supprimer la donnée lors de la pondération)\n",
    "    filo_lcz.loc[\n",
    "        (filo_lcz[\"hre\"] == 0) & (filo_lcz[\"lcz\"].isin([\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"])),\n",
    "        \"hre\"\n",
    "    ] = 4\n",
    "\n",
    "    # On calcule la surface de chaque polygone\n",
    "    filo_lcz[\"surf_id_filo\"] = filo_lcz.geometry.area/10**6\n",
    "    # On calcule le pseudo-volume de chaque polygone\n",
    "    # H : On fait une hyothèse de hauteur de 3m pour les classes A à G (le minimum observé pour LCZ = 9) \n",
    "    # et de densité de 1% (soit 10% de moins que classe 9)// C'est une hypothèse\n",
    "    filo_lcz[\"pseudovol_id_filo\"] = (filo_lcz[\"surf_id_filo\"]*filo_lcz[\"hre\"]*filo_lcz[\"bur\"] \n",
    "                                    * (1-filo_lcz[\"lcz\"].isin([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"])) \n",
    "                                    + filo_lcz[\"lcz\"].isin([\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"])\n",
    "                                    * filo_lcz[\"surf_id_filo\"]*3*1)\n",
    "\n",
    "    ## On présente le découpage de chaque carreau filo en LCZ\n",
    "    filo_lcz_surf = (filo_lcz\n",
    "                    .filter(items=[\"lcz\",\"idcar_200m\",\"surf_id_filo\",\"pseudovol_id_filo\"])\n",
    "                    .groupby([\"idcar_200m\",\"lcz\"])\n",
    "                    .sum()\n",
    "                    .reset_index()\n",
    "                    .pivot_table(index=\"idcar_200m\", \n",
    "                                columns=\"lcz\", \n",
    "                                values=[\"surf_id_filo\",\"pseudovol_id_filo\"], \n",
    "                                fill_value=0)\n",
    "                    .reset_index())\n",
    "    filo_lcz_surf[\"surf_filo\"] = sum([filo_lcz_surf[col] \n",
    "                                    for col in filo_lcz_surf.columns \n",
    "                                    if col[0] == \"surf_id_filo\"])\n",
    "    filo_lcz_surf[\"pseudovol_filo\"] = sum([filo_lcz_surf[col] \n",
    "                                        for col in filo_lcz_surf.columns \n",
    "                                        if col[0] == \"pseudovol_id_filo\"])\n",
    "\n",
    "\n",
    "\n",
    "    ## On calcule la surface totale de chaque carreau\n",
    "    filo_lcz_surf[\"surf_non_constructed\"] = sum([filo_lcz_surf[col] for col in filo_lcz_surf.columns if col[0]== \"surf_id_filo\" and col[1] in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]])\n",
    "    filo_lcz_surf[\"pseudovol_non_constructed\"] = sum([filo_lcz_surf[col] for col in filo_lcz_surf.columns if col[0]== \"pseudovol_id_filo\" and col[1] in [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\"]])\n",
    "    filo_lcz_surf[\"filo_not_constructed\"] = (filo_lcz_surf[\"surf_filo\"] - filo_lcz_surf[\"surf_non_constructed\"]) == 0\n",
    "    filo_lcz_surf[\"filo_sub_flat\"] = filo_lcz_surf[\"filo_not_constructed\"] * filo_lcz_surf[\"surf_filo\"] + (1 - filo_lcz_surf[\"filo_not_constructed\"]) * (filo_lcz_surf[\"surf_filo\"]- filo_lcz_surf[\"surf_non_constructed\"])\n",
    "    # H: On assigne une hauteur de 3m aux surfaces non construites et un taux d'occupation de 1%\n",
    "    filo_lcz_surf[\"filo_sub_psdovol\"] =  filo_lcz_surf[\"filo_not_constructed\"] * filo_lcz_surf[\"pseudovol_filo\"] + (1 - filo_lcz_surf[\"filo_not_constructed\"]) * (filo_lcz_surf[\"pseudovol_filo\"] - filo_lcz_surf[\"pseudovol_non_constructed\"])\n",
    "    ## On garde la table de conversion\n",
    "    to_drop = ['surf_id_filo', 'pseudovol_id_filo']\n",
    "    conversion_table =filo_lcz_surf.drop(columns=filo_lcz_surf.columns[filo_lcz_surf.columns.get_level_values(0).isin(to_drop)])\n",
    "    conversion_table.columns = conversion_table.columns.droplevel(1)\n",
    "\n",
    "    # On fusionnes les carreaux FILO/LCZ avec la table des poids de conversion des données FILO\n",
    "    filo_lcz_w = filo_lcz.merge(conversion_table, on=\"idcar_200m\", how=\"left\")\n",
    "\n",
    "    # On crée une varible binaire pour savoir si le carreau est compté \n",
    "    # H :(on compte les classes non baties lorsque pas de classes baties dans le carreau FILO)\n",
    "    filo_lcz_w['is_accounted'] = (filo_lcz_w[\"lcz\"].isin([\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])) | filo_lcz_w[\"filo_not_constructed\"]\n",
    "    # On calcule le facteur de pondération pour chaque zone\n",
    "    filo_lcz_w[\"flat_w_filo\"]= (filo_lcz_w[\"surf_id_filo\"]/filo_lcz_w[\"filo_sub_flat\"])* filo_lcz_w[\"is_accounted\"]\n",
    "    filo_lcz_w[\"pseudovol_w_filo\"]= (filo_lcz_w[\"pseudovol_id_filo\"]/filo_lcz_w[\"filo_sub_psdovol\"])* filo_lcz_w[\"is_accounted\"]\n",
    "\n",
    "    # On fusionne les carreaux et les données FILOSOFI\n",
    "    filo_lcz_values = filo_lcz_w.merge(filosofi.drop(columns=[\"geometry\",\n",
    "                                        \"idcar_1km\",\n",
    "                                        \"idcar_nat\",\n",
    "                                        \"i_est_200\",\n",
    "                                        \"i_est_1km\",\n",
    "                                        \"lcog_geo\"]),\n",
    "                    on=\"idcar_200m\",\n",
    "                    how=\"left\")\n",
    "\n",
    "    # On calcule les valeurs avec les poids \"plats\"\n",
    "    filo_lcz_values_flat= weighted_filo(filo_lcz_values,\"flat_w_filo\",[\n",
    "        'ind', 'men', 'men_pauv', 'men_1ind', 'men_5ind',\n",
    "        'men_prop', 'men_fmp', 'ind_snv', 'men_surf', 'men_coll', 'men_mais',\n",
    "        'log_av45', 'log_45_70', 'log_70_90', 'log_ap90', 'log_inc', 'log_soc',\n",
    "        'ind_0_3', 'ind_4_5', 'ind_6_10', 'ind_11_17', 'ind_18_24', 'ind_25_39',\n",
    "        'ind_40_54', 'ind_55_64', 'ind_65_79', 'ind_80p', 'ind_inc',\n",
    "    ])\n",
    "\n",
    "    filo_lcz_values_flat.to_csv(os.path.join(prod_dir, \"geo/lcz/filo_com\",''.join([lcz_folders[i],\"-flat-FILO.csv\"])), index=False)\n",
    "\n",
    "    # On calcule les valeurs avec les poids \"volumiques\"\n",
    "    filo_lcz_values_psdovol= weighted_filo(filo_lcz_values,\"pseudovol_w_filo\",[\n",
    "        'ind', 'men', 'men_pauv', 'men_1ind', 'men_5ind',\n",
    "        'men_prop', 'men_fmp', 'ind_snv', 'men_surf', 'men_coll', 'men_mais',\n",
    "        'log_av45', 'log_45_70', 'log_70_90', 'log_ap90', 'log_inc', 'log_soc',\n",
    "        'ind_0_3', 'ind_4_5', 'ind_6_10', 'ind_11_17', 'ind_18_24', 'ind_25_39',\n",
    "        'ind_40_54', 'ind_55_64', 'ind_65_79', 'ind_80p', 'ind_inc',\n",
    "    ])\n",
    "\n",
    "    filo_lcz_values_psdovol.to_csv(os.path.join(prod_dir, \"geo/lcz/filo_com\",''.join([lcz_folders[i],\"-psdovol-FILO.csv\"])), index=False)\n",
    "\n",
    "summary_tot.to_csv(os.path.join(prod_dir, \"geo/lcz\",'summary_lcz_communes.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.3"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 83 / 60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
